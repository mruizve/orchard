{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import mrcnn.utils\n",
    "import mrcnn.model\n",
    "import orchard.dataset\n",
    "import orchard.config\n",
    "import orchard.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004348.182606.Cam6_54.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004348.754118.Cam6_13.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004349.135000.Cam6_11.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004349.516008.Cam6_43.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004351.039789.Cam6_32.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004353.706594.Cam6_22.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004357.135163.Cam6_61.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004357.897055.Cam6_21.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004358.278063.Cam6_62.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004400.563862.Cam6_62.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004406.278234.Cam6_32.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004408.564033.Cam6_41.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004409.706932.Cam6_62.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004414.468907.Cam6_53.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004355.801761.Cam6_12.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004536.946736.Cam6_41.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004427.040535.Cam6_41.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004525.136981.Cam6_22.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004532.184758.Cam6_41.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004532.565766.Cam6_33.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004535.232449.Cam6_43.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004539.042031.Cam6_53.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004546.661320.Cam6_21.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004549.137497.Cam6_21.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004549.899514.Cam6_23.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004551.232791.Cam6_11.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004552.185187.Cam6_52.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004601.709262.Cam6_32.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004604.566446.Cam6_43.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004605.328337.Cam6_72.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004605.709344.Cam6_61.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004605.899724.Cam6_33.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004626.090637.Cam6_24.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005031.238592.Cam6_12.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005038.667371.Cam6_23.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005135.239903.Cam6_74.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005321.527832.Cam6_12.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005425.529158.Cam6_12.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005447.434349.Cam6_62.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005451.053423.Cam6_62.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005104.572657.Cam6_14.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005549.721268.Cam6_53.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005652.008309.Cam6_74.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005652.198812.Cam6_11.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005656.198897.Cam6_72.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005644.770158.Cam6_12.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005654.865494.Cam6_71.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005919.630463.Cam6_61.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T013608.818546_12.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T013638.152395_11.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004424.183355.Cam6_71.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004424.945245.Cam6_32.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004602.661657.Cam6_43.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004546.280311.Cam6_43.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T004603.614052.Cam6_41.png: no annotations to process\n",
      "INFO: skipping image /home/demo/dataset/apples/images/20130320T005658.294191.Cam6_62.png: no annotations to process\n"
     ]
    }
   ],
   "source": [
    "# Training dataset\n",
    "dataset_train = orchard.dataset.OrchardDataset()\n",
    "dataset_train.load(orchard.config.OrchardConfig.DATASET_PATH, 'apples', 'train')\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = orchard.dataset.OrchardDataset()\n",
    "dataset_val.load(orchard.config.OrchardConfig.DATASET_PATH, 'apples', 'val')\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:609: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "Downloading pretrained model to /home/demo/weights/mask_rcnn_coco.h5 ...\n",
      "... done downloading pretrained model!\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/demo/logs/orchard20210107T0031/mask_rcnn_orchard_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "250/250 [==============================] - 109s 435ms/step - loss: 2.0212 - val_loss: 1.8785\n",
      "\n",
      "Starting at epoch 1. LR=0.0001\n",
      "\n",
      "Checkpoint Path: /home/demo/logs/orchard20210107T0031/mask_rcnn_orchard_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "250/250 [==============================] - 206s 822ms/step - loss: 1.4734 - val_loss: 1.6159\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "config = orchard.config.TrainingConfig()\n",
    "#config.display()\n",
    "\n",
    "# Create model in training mode and load weights\n",
    "model = mrcnn.model.MaskRCNN(\n",
    "    mode='training',\n",
    "    config=config,\n",
    "    model_dir=config.LOGS_PATH)\n",
    "orchard.utils.load_weights(model, 'coco')\n",
    "\n",
    "# Train the head branches\n",
    "# Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers\n",
    "# (i.e. the ones that we didn't use pre-trained weights from MS COCO).\n",
    "# To train only the head layers, pass `layers='heads'` to the `train()` to freezes all layers except the head layers.\n",
    "# You can also pass a regular expression to select which layers to train by name pattern.\n",
    "model.train(\n",
    "    dataset_train, dataset_val,\n",
    "    learning_rate=config.LEARNING_RATE,\n",
    "    epochs=config.EPOCHS_HEAD,\n",
    "    layers='heads')\n",
    "\n",
    "# Fine tune all layers\n",
    "# Simply pass `layers=\"all` to train all layers. It is also possible to pass a regular expression to select which\n",
    "# layers to train by name pattern.\n",
    "model.train(\n",
    "    dataset_train, dataset_val,\n",
    "    learning_rate=config.LEARNING_RATE / 10,\n",
    "    epochs=config.EPOCHS_ALL,\n",
    "    layers=\"all\")\n",
    "\n",
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "# weights_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "# model.keras_model.save_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-starting from epoch 2\n",
      "mAP: 0.7019084956284475\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "inference_config = orchard.config.InferenceConfig()\n",
    "#inference_config.display()\n",
    "\n",
    "# Create the model in inference mode and load weights\n",
    "model = mrcnn.model.MaskRCNN(\n",
    "    mode='inference',\n",
    "    config=inference_config,\n",
    "    model_dir=inference_config.LOGS_PATH)\n",
    "orchard.utils.load_weights(model, 'last')\n",
    "\n",
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 100 images. Increase for better accuracy.\n",
    "APs = []\n",
    "for image_id in dataset_val.image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask = mrcnn.model.load_image_gt(\n",
    "        dataset_val,\n",
    "        inference_config,\n",
    "        image_id,\n",
    "        use_mini_mask=False)\n",
    "\n",
    "    molded_images = np.expand_dims(mrcnn.model.mold_image(image, inference_config), 0)\n",
    "\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "\n",
    "    r = results[0]\n",
    "\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps = mrcnn.utils.compute_ap(\n",
    "        gt_bbox,\n",
    "        gt_class_id,\n",
    "        gt_mask,\n",
    "        r['rois'], r['class_ids'], r['scores'], r['masks'])\n",
    "    APs.append(AP)\n",
    "print('mAP: {}'.format(np.mean(APs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
